{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTxnC0miCqp8"
   },
   "source": [
    "## Day3 CNN with DNA sequence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpXtbI5kBkOr"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "- Developing a CNN Model for classifying sequences \n",
    "- Example: Developing a model to identify specific DNA motifs bound by an arbitrary transcription factor. The model predicts whether a given transcription factor binds to an input DNA sequence (output: 1) or not (output: 0).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2M0_b-DM_xnq"
   },
   "source": [
    "## Data\n",
    "\n",
    "- To train a deep learning model, labeled data is required (though not always necessary in modern self-supervised learning approaches). \n",
    "- In sequence analysis, DNA sequences paired with their corresponding phenotypes can serve as labeled data (genotype-phenotype paired data).\n",
    "  - For example, to train a deep learning model to predict DNA sequences bound by a specific transcription factor, you would need a dataset containing transcription factor sequence data along with labels indicating whether or not the transcription factor binds to a given DNA sequence (True or False).\n",
    "\n",
    "- Generally, data for statistical analysis is represented as a 2D array, with rows corresponding to samples and columns to variables. In deep learning, data is represented in the same way. The number of samples required depends on the complexity of the model, but typically, at least thousands of samples are needed. Using tens of thousands or more samples is recommended for optimal results.\n",
    "\n",
    "- A dataset collected for deep learning is divided into training and test datasets. Sometimes, the training dataset is further split into training and validation datasets for model development and performance evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YGDLROF-Dzl"
   },
   "source": [
    "### One-hot encoding\n",
    "\n",
    "\n",
    "- For deep learning, data must be represented numerically in a format that machines can process. \n",
    "- One-hot encoding is one of the most widely used methods in deep learning.\n",
    "- For DNA sequences with four types of nucleotides, encoding can be done as follows:  \n",
    "\n",
    "    - \"A\" → [1, 0, 0, 0]  \n",
    "    - \"T\" → [0, 0, 0, 1]  \n",
    "    - \"G\" → [0, 0, 1, 0]  \n",
    "    - \"C\" → [0, 1, 0, 0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1718611149169,
     "user": {
      "displayName": "haseong kim",
      "userId": "15555769759698200025"
     },
     "user_tz": -540
    },
    "id": "isvqkRHO-B0I",
    "outputId": "ba81a254-f3b1-4363-a80b-6fe80bd66b07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A' 'T' 'A' 'C' 'A' 'A']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "my_string=\"ATACAA\"\n",
    "my_array=np.array(list(my_string))\n",
    "print(my_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1718590631032,
     "user": {
      "displayName": "haseong kim",
      "userId": "15555769759698200025"
     },
     "user_tz": -540
    },
    "id": "SU0BhAF2-4Wu",
    "outputId": "9bca6e54-ca39-4ab6-bfc7-71c6e06850cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'T', 'A', 'C', 'A', 'A']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "executionInfo": {
     "elapsed": 477,
     "status": "ok",
     "timestamp": 1718612057122,
     "user": {
      "displayName": "haseong kim",
      "userId": "15555769759698200025"
     },
     "user_tz": -540
    },
    "id": "VPXw4xGZ_ACy",
    "outputId": "d6631d4c-97df-49fc-f73f-8782082280b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((7,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 627,
     "status": "ok",
     "timestamp": 1718612507345,
     "user": {
      "displayName": "haseong kim",
      "userId": "15555769759698200025"
     },
     "user_tz": -540
    },
    "id": "BKSRQ4AmNVGD",
    "outputId": "ef64187d-d85b-41ba-e89d-08eeb191ad11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box = np.zeros((3, 7, 5))\n",
    "type(box)\n",
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 644,
     "status": "ok",
     "timestamp": 1718613208155,
     "user": {
      "displayName": "haseong kim",
      "userId": "15555769759698200025"
     },
     "user_tz": -540
    },
    "id": "OzX1nU6m-1fE",
    "outputId": "c7c8132e-a663-4d72-92cc-99c1c35daae9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0]\n",
      " [0 0 0 1]\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]]\n",
      "(6, 4)\n"
     ]
    }
   ],
   "source": [
    "onehot_encode = np.zeros((len(my_array),4), dtype=int)\n",
    "base_dict = {\"A\":0, \"C\":1, \"G\":2, \"T\":3}\n",
    "for i in range(len(my_array)):\n",
    "    onehot_encode[i, base_dict[my_array[i]]] = 1\n",
    "\n",
    "print(onehot_encode)\n",
    "print(onehot_encode.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5vnHIXbBPTj"
   },
   "source": [
    "### Set sequence motif for simulation\n",
    "\n",
    "- Understanding the concepts of PFM (Position Frequency Matrix) and PWM (Position Weight Matrix) is essential. \n",
    "- Assuming an alignment of several sequences, the PFM represents the frequency of each nucleotide (A, T, G, C) at specific positions in the sequences, while the PWM represents the proportion of each nucleotide at those positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1718614750161,
     "user": {
      "displayName": "haseong kim",
      "userId": "15555769759698200025"
     },
     "user_tz": -540
    },
    "id": "bHWovtkJ_qxL",
    "outputId": "449e3397-7aed-4272-8737-9896233f5e45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0      1      2      3      4\n",
      "A:   0.00   3.00   0.00   2.00   3.00\n",
      "C:   0.00   0.00   3.00   0.00   0.00\n",
      "G:   0.00   0.00   0.00   1.00   0.00\n",
      "T:   3.00   0.00   0.00   0.00   0.00\n",
      "\n",
      "        0      1      2      3      4\n",
      "A:   0.10   0.70   0.10   0.50   0.70\n",
      "C:   0.10   0.10   0.70   0.10   0.10\n",
      "G:   0.10   0.10   0.10   0.30   0.10\n",
      "T:   0.70   0.10   0.10   0.10   0.10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from Bio import motifs\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "instances = [Seq(\"TACAA\"), Seq(\"TACGA\"), Seq(\"TACAA\")]\n",
    "m = motifs.create(instances)\n",
    "pfm = m.counts\n",
    "print(pfm)\n",
    "pwm = m.counts.normalize(pseudocounts=0.5)\n",
    "print (pwm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_ALRfQsD_Gi"
   },
   "source": [
    "- Pseudocounts are used in calculations to avoid division by NULL or zero. \n",
    "- The PWM (Position Weight Matrix) of a specific sequence motif can be used to search for the motif's location in a new sequence provided in one-hot encoding format. \n",
    "- Using a sliding window approach, the motif can be scanned from the beginning to the end of the sequence to identify its presence. \n",
    "- The following demonstrates how to detect the presence of a given PWM motif (assuming a binary 0 and 1 representation) in a sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/dnacnn2.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If there is a '5' in the length-3 array as shown above, it indicates that the target sequence contains a sequence matching the motif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To search for the presence of the PWM motif in the sequence \"ATACAA,\" a sliding window of length 5 can be used to divide the sequence into two sub-sequences: \"ATACA\" and \"TACAA.\" \n",
    "  - By converting these two sub-sequences into one-hot encoding and multiplying their elements with the corresponding elements of the PWM, only the PWM values at the non-zero positions of the one-hot encoding remain. \n",
    "  - To quantify how similar a given sequence is to the motif: 1. Multiply all non-zero values from the PWM.  2. Take the logarithm of the result.\n",
    "  - The resulting scalar value indicates the similarity between the sequence and the motif. Theoretically, a value of 0 implies an identical sequence match to the motif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 400,
     "status": "ok",
     "timestamp": 1718615793292,
     "user": {
      "displayName": "haseong kim",
      "userId": "15555769759698200025"
     },
     "user_tz": -540
    },
    "id": "XQYZQfcECkuT",
    "outputId": "b174a1d2-8526-44f7-d48a-e536955392b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4)\n",
      "(6, 4)\n",
      "(5, 4)\n",
      "(5, 4)\n",
      "[[0.1 0.  0.  0. ]\n",
      " [0.  0.  0.  0.1]\n",
      " [0.1 0.  0.  0. ]\n",
      " [0.  0.1 0.  0. ]\n",
      " [0.7 0.  0.  0. ]]\n",
      "[[0.  0.  0.  0.7]\n",
      " [0.7 0.  0.  0. ]\n",
      " [0.  0.7 0.  0. ]\n",
      " [0.5 0.  0.  0. ]\n",
      " [0.7 0.  0.  0. ]]\n",
      "[0.1 0.1 0.1 0.1 0.7]\n",
      "7.000000000000002e-05\n",
      "-9.567015315914915\n",
      "-2.119846956314875\n"
     ]
    }
   ],
   "source": [
    "pwm_arr = np.array(list(pwm.values())).transpose()\n",
    "print(pwm_arr.shape)\n",
    "\n",
    "print(onehot_encode.shape)\n",
    "print(onehot_encode[0:5,].shape)\n",
    "print(onehot_encode[1:6,].shape)\n",
    "\n",
    "s1 = np.multiply(onehot_encode[0:5,], pwm_arr)\n",
    "s2 = np.multiply(onehot_encode[1:6,], pwm_arr)\n",
    "print(s1)\n",
    "print(s2)\n",
    "\n",
    "print(np.sum(s1, axis=1))\n",
    "print(np.prod(np.sum(s1, axis=1)))\n",
    "\n",
    "print(np.log(np.prod(np.sum(s1, axis=1)))) #s1 score\n",
    "print(np.log(np.prod(np.sum(s2, axis=1)))) #s2 score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deep learning styled array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/deeplearning_dim.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3XK9LAjGJpm"
   },
   "source": [
    "### Simulation data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 1,000 simulated positive sequences by embedding a motif in the middle of the sequences, and 1,000 negative sequences with random DNA sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "executionInfo": {
     "elapsed": 551,
     "status": "ok",
     "timestamp": 1718616329999,
     "user": {
      "displayName": "haseong kim",
      "userId": "15555769759698200025"
     },
     "user_tz": -540
    },
    "id": "SXLlovgLDbu1",
    "outputId": "5308cbe2-4126-4bbe-fb35-fced89858523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['GGATTAAACGGAAACTATTT',\n",
       " 'AAGACTGCCGGATGGGCTCG',\n",
       " 'CCCGAAGGCGGAAACAATCT',\n",
       " 'ATGGAAGCGGGAAATATTCT']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['CTACCCTTACTCGCAGGGAA',\n",
       " 'ACTCACTAATTGGATTGAGA',\n",
       " 'AGGTACCTCGCGGCATCTGG',\n",
       " 'GGTATCTACGTGAAGAAGGG']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "seq_length = 20\n",
    "num_sample = 1000\n",
    "#motif CCGGAA\n",
    "motif_pwm = np.array([[10.41, 22.86, 1.92, 1.55, 98.60, 86.66],\n",
    "            [68.20, 65.25, 0.50, 0.35, 0.25, 2.57],\n",
    "            [17.27, 8.30, 94.77, 97.32, 0.87, 0.00],\n",
    "            [4.13, 3.59, 2.81, 0.78, 0.28, 10.77]])\n",
    "pwm = np.hstack([np.ones((4, 7)), motif_pwm, np.ones((4, 7))])\n",
    "pos = np.array([np.random.choice( ['A', 'C', 'G', 'T'], num_sample,\n",
    "                                  p=pwm[:,i]/sum(pwm[:,i])) for i in range(seq_length)]).transpose()\n",
    "neg = np.array([np.random.choice( ['A', 'C', 'G', 'T'], num_sample,\n",
    "                                  p=np.array([1,1,1,1])/4) for i in range(seq_length)]).transpose()\n",
    "\n",
    "print(pos.shape)\n",
    "display([''.join(x) for x in pos[1:5,]])\n",
    "print()\n",
    "display([''.join(x) for x in neg[1:5,]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21DUbOCjHSxX"
   },
   "source": [
    "### DNA data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 571,
     "status": "ok",
     "timestamp": 1718616340829,
     "user": {
      "displayName": "haseong kim",
      "userId": "15555769759698200025"
     },
     "user_tz": -540
    },
    "id": "V6m6Sc2vHU1e",
    "outputId": "1b21955b-952e-492e-ac35-2005af2426fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 20, 4) (2000, 2)\n"
     ]
    }
   ],
   "source": [
    "base_dict = {'A':0, 'C':1, 'G':2, 'T':3}\n",
    "\n",
    "# response variable for pos\n",
    "onehot_encode_pos = np.zeros((num_sample, seq_length, 4))\n",
    "onehot_encode_pos_label = np.zeros((num_sample, 2), dtype=int)\n",
    "onehot_encode_pos_label[:,0] = 1\n",
    "# print(onehot_encode_pos_label)\n",
    "\n",
    "# response variable for pos\n",
    "onehot_encode_neg = np.zeros((num_sample, seq_length, 4))\n",
    "onehot_encode_neg_label = np.zeros((num_sample, 2), dtype=int)\n",
    "onehot_encode_neg_label[:,1] = 1\n",
    "# print(onehot_encode_neg_label)\n",
    "\n",
    "# convert sequence to onehot\n",
    "for i in range(num_sample):\n",
    "    for j in range(seq_length):\n",
    "        onehot_encode_pos[i,j,base_dict[pos[i,j]]] = 1\n",
    "        onehot_encode_neg[i,j,base_dict[neg[i,j]]] = 1\n",
    "\n",
    "# concatenation\n",
    "X = np.vstack((onehot_encode_pos, onehot_encode_neg))\n",
    "y = np.vstack((onehot_encode_pos_label, onehot_encode_neg_label))\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "# (2000, 20, 4) (2000, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PyTorch Conv1d requires [batch_size, channels, length] so transpose(1,2) excuted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1718616362356,
     "user": {
      "displayName": "haseong kim",
      "userId": "15555769759698200025"
     },
     "user_tz": -540
    },
    "id": "q9gHKkkbHaEF",
    "outputId": "0481cce5-7585-4ba5-a715-728681c165a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 20, 4) (1600, 2)\n",
      "torch.float32\n",
      "torch.Size([1600, 4, 20])\n",
      "torch.Size([1600, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터를 훈련 세트와 테스트 세트로 나눔\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=125)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "# NumPy 배열을 PyTorch 텐서로 변환\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).transpose(1,2)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).transpose(1,2)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "print(y_test.dtype)\n",
    "\n",
    "# DataLoader 설정\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "print(train_loader.dataset.tensors[0].shape)\n",
    "print(train_loader.dataset.tensors[1].shape)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 610,
     "status": "ok",
     "timestamp": 1718616374501,
     "user": {
      "displayName": "haseong kim",
      "userId": "15555769759698200025"
     },
     "user_tz": -540
    },
    "id": "mThrgCyGSsfq",
    "outputId": "4ba6d7d9-42d0-42ac-e404-39002de8e4a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1600, 4, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2688/3124571761.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_torch = torch.tensor(X_train, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X_torch = torch.tensor(X_train, dtype=torch.float32)\n",
    "print(X_torch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aROVZUbXWwg1"
   },
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1718616387856,
     "user": {
      "displayName": "haseong kim",
      "userId": "15555769759698200025"
     },
     "user_tz": -540
    },
    "id": "GewjG62iUvYk",
    "outputId": "8394d97a-bb14-4e7b-c02c-976f8835f870"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 16, 20]             208\n",
      "              ReLU-2               [-1, 16, 20]               0\n",
      "         MaxPool1d-3               [-1, 16, 10]               0\n",
      "           Flatten-4                  [-1, 160]               0\n",
      "            Linear-5                   [-1, 64]          10,304\n",
      "            Linear-6                    [-1, 2]             130\n",
      "================================================================\n",
      "Total params: 10,642\n",
      "Trainable params: 10,642\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 0.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class DNA_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNA_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(160, 64)  # Adjust the input features according to your pooling and conv1d output\n",
    "        self.fc2 = nn.Linear(64, 2)  # Adjust according to your problem's needs (e.g., number of classes)\n",
    "        #self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        #x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "model = DNA_CNN()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(4, 20))  # (Channels, Length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "218_FeCtW0kZ"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2915,
     "status": "ok",
     "timestamp": 1718617108099,
     "user": {
      "displayName": "haseong kim",
      "userId": "15555769759698200025"
     },
     "user_tz": -540
    },
    "id": "2DxWgtlAW0Jy",
    "outputId": "96aea657-d7d9-4569-881a-e3c256d7cd94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.5050\n",
      "Epoch [2/20], Loss: 0.2472\n",
      "Epoch [3/20], Loss: 0.1437\n",
      "Epoch [4/20], Loss: 0.0821\n",
      "Epoch [5/20], Loss: 0.0966\n",
      "Epoch [6/20], Loss: 0.0719\n",
      "Epoch [7/20], Loss: 0.0729\n",
      "Epoch [8/20], Loss: 0.0387\n",
      "Epoch [9/20], Loss: 0.1018\n",
      "Epoch [10/20], Loss: 0.1520\n",
      "Epoch [11/20], Loss: 0.0712\n",
      "Epoch [12/20], Loss: 0.0277\n",
      "Epoch [13/20], Loss: 0.0272\n",
      "Epoch [14/20], Loss: 0.0318\n",
      "Epoch [15/20], Loss: 0.0215\n",
      "Epoch [16/20], Loss: 0.0464\n",
      "Epoch [17/20], Loss: 0.0975\n",
      "Epoch [18/20], Loss: 0.0566\n",
      "Epoch [19/20], Loss: 0.0191\n",
      "Epoch [20/20], Loss: 0.0516\n"
     ]
    }
   ],
   "source": [
    "# 훈련 루프\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        if torch.cuda.is_available():\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 365,
     "status": "ok",
     "timestamp": 1718617327293,
     "user": {
      "displayName": "haseong kim",
      "userId": "15555769759698200025"
     },
     "user_tz": -540
    },
    "id": "07_QpQsBo-SR",
    "outputId": "66c7ede7-5ece-4860-b705-3f3466044a52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 98.5 %\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        if torch.cuda.is_available():\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        outputs = model(inputs)\n",
    "        #print(outputs.data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        #print(predicted)\n",
    "        total += labels.size(0)\n",
    "        labels_max = torch.max(labels, 1)[1]\n",
    "        #print(labels_max)\n",
    "        correct += (predicted == labels_max).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the model on the test images: {100 * correct / total} %')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcJPfqdylWXm"
   },
   "source": [
    "## Training and evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 25207,
     "status": "ok",
     "timestamp": 1718617527334,
     "user": {
      "displayName": "haseong kim",
      "userId": "15555769759698200025"
     },
     "user_tz": -540
    },
    "id": "UjEkmdVRlJm4",
    "outputId": "73928f73-3d07-43b9-dbc9-bcded72386d8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     10\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 저장을 위한 리스트 초기화\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        if torch.cuda.is_available():\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    train_losses.append(epoch_loss)\n",
    "\n",
    "    # 모델 평가\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            labels_max = torch.max(labels, 1)[1]\n",
    "            correct += (predicted == labels_max).sum().item()\n",
    "\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    val_accuracies.append(epoch_accuracy)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "\n",
    "# 그래프 그리기\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO2AgYT1PZj0OXviRPDdbV1",
   "mount_file_id": "1E8yPlQgPbwnW3d2P1XeUD22Zz7rl3cZr",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "kaist-prog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
